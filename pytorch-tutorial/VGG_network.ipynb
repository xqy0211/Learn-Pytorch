{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "     transforms.RandomHorizontalFlip(),\n",
    "     transforms.RandomGrayscale(),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "transform1 = transforms.Compose(\n",
    "    [\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=False, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=False, transform=transform1)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=50,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        describe:基于VGG16，提出输入224x224x3，所以这里会出现维度的奇偶不匹配\n",
    "        \"\"\"\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,64,3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(64,64,3,padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64,128,3,padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 128, 3,padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        self.conv5 = nn.Conv2d(128,128, 3,padding=1)\n",
    "        self.conv6 = nn.Conv2d(128, 128, 3,padding=1)\n",
    "        self.conv7 = nn.Conv2d(128, 128, 1,padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        self.conv8 = nn.Conv2d(128, 256, 3,padding=1)\n",
    "        self.conv9 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.conv10 = nn.Conv2d(256, 256, 1, padding=1)\n",
    "        self.pool4 = nn.MaxPool2d(2, 2, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.relu4 = nn.ReLU()\n",
    "\n",
    "        self.conv11 = nn.Conv2d(256, 512, 3, padding=1)\n",
    "        self.conv12 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.conv13 = nn.Conv2d(512, 512, 1, padding=1)\n",
    "        self.pool5 = nn.MaxPool2d(2, 2, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(512)\n",
    "        self.relu5 = nn.ReLU()\n",
    "\n",
    "        self.fc14 = nn.Linear(512*4*4,1024)\n",
    "        self.drop1 = nn.Dropout2d()\n",
    "        self.fc15 = nn.Linear(1024,1024)\n",
    "        self.drop2 = nn.Dropout2d()\n",
    "        self.fc16 = nn.Linear(1024,10)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "        describe:\n",
    "        input(100,3,32,32) -> conv1 (100,64,32,32)-> conv2 -> pool1(100,64,16,16) -> \n",
    "        conv3(100,128,16,16) -> conv4 -> pool2(100,128,9,9) -> \n",
    "        conv5 -> conv6 -> conv7(100,128,11,11) -> maxpool3(100,128,6,6) -> \n",
    "        conv8(100,256,6,6) -> conv9 -> conv10(100,256,8,8) -> pool4(100,256,5,5) ->\n",
    "        conv11(100,512,5,5) -> conv12 -> conv13 (100,512,7,7)-> pool5(100,512,4,4) -> \n",
    "        reshape(100,512x4x4) -> fc14(100,1024) -> fc15 -> fc16(100,10) -> output\n",
    "        \"\"\"\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.conv7(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu3(x)\n",
    "\n",
    "        x = self.conv8(x)\n",
    "        x = self.conv9(x)\n",
    "        x = self.conv10(x)\n",
    "        x = self.pool4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu4(x)\n",
    "\n",
    "        x = self.conv11(x)\n",
    "        x = self.conv12(x)\n",
    "        x = self.conv13(x)\n",
    "        x = self.pool5(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.relu5(x)\n",
    "        # print(\" x shape \",x.size())\n",
    "        x = x.view(-1,512*4*4)\n",
    "        x = F.relu(self.fc14(x))\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(self.fc15(x))\n",
    "        x = self.drop2(x)\n",
    "        x = self.fc16(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU()\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU()\n",
      "  (conv5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv7): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu3): ReLU()\n",
      "  (conv8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv10): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu4): ReLU()\n",
      "  (conv11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv12): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv13): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "  (pool5): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (bn5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu5): ReLU()\n",
      "  (fc14): Linear(in_features=8192, out_features=1024, bias=True)\n",
      "  (drop1): Dropout2d(p=0.5)\n",
      "  (fc15): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (drop2): Dropout2d(p=0.5)\n",
      "  (fc16): Linear(in_features=1024, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net().to(device)\n",
    "print(net)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(self.parameters(),lr=0.01)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "\n",
    "def update_lr(optimizer, lr):    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/100], Step: [100/500], Loss: 1.6203\n",
      "Epoch: [1/100], Step: [200/500], Loss: 1.4013\n",
      "Epoch: [1/100], Step: [300/500], Loss: 1.4038\n",
      "Epoch: [1/100], Step: [400/500], Loss: 1.0145\n",
      "Epoch: [1/100], Step: [500/500], Loss: 0.8920\n",
      "Epoch: [2/100], Step: [100/500], Loss: 1.2093\n",
      "Epoch: [2/100], Step: [200/500], Loss: 1.2170\n",
      "Epoch: [2/100], Step: [300/500], Loss: 1.0429\n",
      "Epoch: [2/100], Step: [400/500], Loss: 0.8567\n",
      "Epoch: [2/100], Step: [500/500], Loss: 0.8855\n",
      "Epoch: [3/100], Step: [100/500], Loss: 0.8823\n",
      "Epoch: [3/100], Step: [200/500], Loss: 0.7478\n",
      "Epoch: [3/100], Step: [300/500], Loss: 0.7270\n",
      "Epoch: [3/100], Step: [400/500], Loss: 0.6535\n",
      "Epoch: [3/100], Step: [500/500], Loss: 0.7517\n",
      "Epoch: [4/100], Step: [100/500], Loss: 0.9052\n",
      "Epoch: [4/100], Step: [200/500], Loss: 0.5992\n",
      "Epoch: [4/100], Step: [300/500], Loss: 0.7525\n",
      "Epoch: [4/100], Step: [400/500], Loss: 0.4795\n",
      "Epoch: [4/100], Step: [500/500], Loss: 0.4614\n",
      "Epoch: [5/100], Step: [100/500], Loss: 0.6441\n",
      "Epoch: [5/100], Step: [200/500], Loss: 0.5049\n",
      "Epoch: [5/100], Step: [300/500], Loss: 0.4870\n",
      "Epoch: [5/100], Step: [400/500], Loss: 0.4698\n",
      "Epoch: [5/100], Step: [500/500], Loss: 0.5489\n",
      "Epoch: [6/100], Step: [100/500], Loss: 0.4355\n",
      "Epoch: [6/100], Step: [200/500], Loss: 0.3762\n",
      "Epoch: [6/100], Step: [300/500], Loss: 0.4525\n",
      "Epoch: [6/100], Step: [400/500], Loss: 0.5892\n",
      "Epoch: [6/100], Step: [500/500], Loss: 0.5050\n",
      "Epoch: [7/100], Step: [100/500], Loss: 0.4360\n",
      "Epoch: [7/100], Step: [200/500], Loss: 0.5248\n",
      "Epoch: [7/100], Step: [300/500], Loss: 0.4908\n",
      "Epoch: [7/100], Step: [400/500], Loss: 0.5481\n",
      "Epoch: [7/100], Step: [500/500], Loss: 0.3203\n",
      "Epoch: [8/100], Step: [100/500], Loss: 0.4189\n",
      "Epoch: [8/100], Step: [200/500], Loss: 0.4297\n",
      "Epoch: [8/100], Step: [300/500], Loss: 0.4419\n",
      "Epoch: [8/100], Step: [400/500], Loss: 0.4112\n",
      "Epoch: [8/100], Step: [500/500], Loss: 0.4219\n",
      "Epoch: [9/100], Step: [100/500], Loss: 0.2669\n",
      "Epoch: [9/100], Step: [200/500], Loss: 0.3762\n",
      "Epoch: [9/100], Step: [300/500], Loss: 0.3604\n",
      "Epoch: [9/100], Step: [400/500], Loss: 0.2214\n",
      "Epoch: [9/100], Step: [500/500], Loss: 0.4262\n",
      "Epoch: [10/100], Step: [100/500], Loss: 0.3222\n",
      "Epoch: [10/100], Step: [200/500], Loss: 0.4429\n",
      "Epoch: [10/100], Step: [300/500], Loss: 0.4275\n",
      "Epoch: [10/100], Step: [400/500], Loss: 0.4258\n",
      "Epoch: [10/100], Step: [500/500], Loss: 0.4279\n",
      "Epoch: [11/100], Step: [100/500], Loss: 0.2906\n",
      "Epoch: [11/100], Step: [200/500], Loss: 0.3306\n",
      "Epoch: [11/100], Step: [300/500], Loss: 0.4067\n",
      "Epoch: [11/100], Step: [400/500], Loss: 0.4006\n",
      "Epoch: [11/100], Step: [500/500], Loss: 0.3652\n",
      "Epoch: [12/100], Step: [100/500], Loss: 0.2643\n",
      "Epoch: [12/100], Step: [200/500], Loss: 0.2683\n",
      "Epoch: [12/100], Step: [300/500], Loss: 0.2442\n",
      "Epoch: [12/100], Step: [400/500], Loss: 0.1586\n",
      "Epoch: [12/100], Step: [500/500], Loss: 0.3284\n",
      "Epoch: [13/100], Step: [100/500], Loss: 0.3019\n",
      "Epoch: [13/100], Step: [200/500], Loss: 0.1883\n",
      "Epoch: [13/100], Step: [300/500], Loss: 0.3728\n",
      "Epoch: [13/100], Step: [400/500], Loss: 0.2518\n",
      "Epoch: [13/100], Step: [500/500], Loss: 0.4277\n",
      "Epoch: [14/100], Step: [100/500], Loss: 0.3225\n",
      "Epoch: [14/100], Step: [200/500], Loss: 0.3665\n",
      "Epoch: [14/100], Step: [300/500], Loss: 0.2032\n",
      "Epoch: [14/100], Step: [400/500], Loss: 0.2550\n",
      "Epoch: [14/100], Step: [500/500], Loss: 0.3635\n",
      "Epoch: [15/100], Step: [100/500], Loss: 0.2797\n",
      "Epoch: [15/100], Step: [200/500], Loss: 0.2063\n",
      "Epoch: [15/100], Step: [300/500], Loss: 0.2496\n",
      "Epoch: [15/100], Step: [400/500], Loss: 0.4072\n",
      "Epoch: [15/100], Step: [500/500], Loss: 0.2561\n",
      "Epoch: [16/100], Step: [100/500], Loss: 0.2352\n",
      "Epoch: [16/100], Step: [200/500], Loss: 0.1533\n",
      "Epoch: [16/100], Step: [300/500], Loss: 0.2180\n",
      "Epoch: [16/100], Step: [400/500], Loss: 0.1743\n",
      "Epoch: [16/100], Step: [500/500], Loss: 0.1888\n",
      "Epoch: [17/100], Step: [100/500], Loss: 0.2339\n",
      "Epoch: [17/100], Step: [200/500], Loss: 0.2272\n",
      "Epoch: [17/100], Step: [300/500], Loss: 0.2795\n",
      "Epoch: [17/100], Step: [400/500], Loss: 0.2147\n",
      "Epoch: [17/100], Step: [500/500], Loss: 0.1514\n",
      "Epoch: [18/100], Step: [100/500], Loss: 0.2172\n",
      "Epoch: [18/100], Step: [200/500], Loss: 0.1288\n",
      "Epoch: [18/100], Step: [300/500], Loss: 0.0820\n",
      "Epoch: [18/100], Step: [400/500], Loss: 0.3054\n",
      "Epoch: [18/100], Step: [500/500], Loss: 0.1890\n",
      "Epoch: [19/100], Step: [100/500], Loss: 0.1609\n",
      "Epoch: [19/100], Step: [200/500], Loss: 0.1149\n",
      "Epoch: [19/100], Step: [300/500], Loss: 0.2797\n",
      "Epoch: [19/100], Step: [400/500], Loss: 0.3263\n",
      "Epoch: [19/100], Step: [500/500], Loss: 0.1929\n",
      "Epoch: [20/100], Step: [100/500], Loss: 0.1571\n",
      "Epoch: [20/100], Step: [200/500], Loss: 0.2066\n",
      "Epoch: [20/100], Step: [300/500], Loss: 0.1773\n",
      "Epoch: [20/100], Step: [400/500], Loss: 0.3009\n",
      "Epoch: [20/100], Step: [500/500], Loss: 0.2101\n",
      "Epoch: [21/100], Step: [100/500], Loss: 0.2031\n",
      "Epoch: [21/100], Step: [200/500], Loss: 0.2448\n",
      "Epoch: [21/100], Step: [300/500], Loss: 0.2866\n",
      "Epoch: [21/100], Step: [400/500], Loss: 0.2720\n",
      "Epoch: [21/100], Step: [500/500], Loss: 0.1077\n",
      "Epoch: [22/100], Step: [100/500], Loss: 0.1655\n",
      "Epoch: [22/100], Step: [200/500], Loss: 0.1683\n",
      "Epoch: [22/100], Step: [300/500], Loss: 0.2411\n",
      "Epoch: [22/100], Step: [400/500], Loss: 0.0786\n",
      "Epoch: [22/100], Step: [500/500], Loss: 0.1937\n",
      "Epoch: [23/100], Step: [100/500], Loss: 0.2888\n",
      "Epoch: [23/100], Step: [200/500], Loss: 0.1661\n",
      "Epoch: [23/100], Step: [300/500], Loss: 0.1711\n",
      "Epoch: [23/100], Step: [400/500], Loss: 0.2296\n",
      "Epoch: [23/100], Step: [500/500], Loss: 0.1291\n",
      "Epoch: [24/100], Step: [100/500], Loss: 0.1506\n",
      "Epoch: [24/100], Step: [200/500], Loss: 0.3200\n",
      "Epoch: [24/100], Step: [300/500], Loss: 0.1867\n",
      "Epoch: [24/100], Step: [400/500], Loss: 0.2510\n",
      "Epoch: [24/100], Step: [500/500], Loss: 0.1268\n",
      "Epoch: [25/100], Step: [100/500], Loss: 0.1147\n",
      "Epoch: [25/100], Step: [200/500], Loss: 0.1096\n",
      "Epoch: [25/100], Step: [300/500], Loss: 0.1046\n",
      "Epoch: [25/100], Step: [400/500], Loss: 0.1026\n",
      "Epoch: [25/100], Step: [500/500], Loss: 0.2880\n",
      "Epoch: [26/100], Step: [100/500], Loss: 0.1790\n",
      "Epoch: [26/100], Step: [200/500], Loss: 0.1609\n",
      "Epoch: [26/100], Step: [300/500], Loss: 0.1144\n",
      "Epoch: [26/100], Step: [400/500], Loss: 0.2673\n",
      "Epoch: [26/100], Step: [500/500], Loss: 0.1188\n",
      "Epoch: [27/100], Step: [100/500], Loss: 0.1320\n",
      "Epoch: [27/100], Step: [200/500], Loss: 0.0817\n",
      "Epoch: [27/100], Step: [300/500], Loss: 0.1603\n",
      "Epoch: [27/100], Step: [400/500], Loss: 0.2264\n",
      "Epoch: [27/100], Step: [500/500], Loss: 0.0738\n",
      "Epoch: [28/100], Step: [100/500], Loss: 0.0658\n",
      "Epoch: [28/100], Step: [200/500], Loss: 0.2215\n",
      "Epoch: [28/100], Step: [300/500], Loss: 0.2052\n",
      "Epoch: [28/100], Step: [400/500], Loss: 0.0640\n",
      "Epoch: [28/100], Step: [500/500], Loss: 0.2156\n",
      "Epoch: [29/100], Step: [100/500], Loss: 0.1219\n",
      "Epoch: [29/100], Step: [200/500], Loss: 0.1468\n",
      "Epoch: [29/100], Step: [300/500], Loss: 0.0768\n",
      "Epoch: [29/100], Step: [400/500], Loss: 0.0920\n",
      "Epoch: [29/100], Step: [500/500], Loss: 0.1092\n",
      "Epoch: [30/100], Step: [100/500], Loss: 0.0824\n",
      "Epoch: [30/100], Step: [200/500], Loss: 0.1265\n",
      "Epoch: [30/100], Step: [300/500], Loss: 0.2124\n",
      "Epoch: [30/100], Step: [400/500], Loss: 0.1348\n",
      "Epoch: [30/100], Step: [500/500], Loss: 0.1075\n",
      "Epoch: [31/100], Step: [100/500], Loss: 0.0955\n",
      "Epoch: [31/100], Step: [200/500], Loss: 0.1475\n",
      "Epoch: [31/100], Step: [300/500], Loss: 0.0913\n",
      "Epoch: [31/100], Step: [400/500], Loss: 0.1251\n",
      "Epoch: [31/100], Step: [500/500], Loss: 0.0648\n",
      "Epoch: [32/100], Step: [100/500], Loss: 0.0657\n",
      "Epoch: [32/100], Step: [200/500], Loss: 0.0397\n",
      "Epoch: [32/100], Step: [300/500], Loss: 0.1828\n",
      "Epoch: [32/100], Step: [400/500], Loss: 0.1271\n",
      "Epoch: [32/100], Step: [500/500], Loss: 0.0901\n",
      "Epoch: [33/100], Step: [100/500], Loss: 0.1047\n",
      "Epoch: [33/100], Step: [200/500], Loss: 0.0940\n",
      "Epoch: [33/100], Step: [300/500], Loss: 0.1109\n",
      "Epoch: [33/100], Step: [400/500], Loss: 0.1111\n",
      "Epoch: [33/100], Step: [500/500], Loss: 0.0287\n",
      "Epoch: [34/100], Step: [100/500], Loss: 0.1009\n",
      "Epoch: [34/100], Step: [200/500], Loss: 0.1209\n",
      "Epoch: [34/100], Step: [300/500], Loss: 0.1214\n",
      "Epoch: [34/100], Step: [400/500], Loss: 0.0955\n",
      "Epoch: [34/100], Step: [500/500], Loss: 0.0598\n",
      "Epoch: [35/100], Step: [100/500], Loss: 0.0552\n",
      "Epoch: [35/100], Step: [200/500], Loss: 0.0265\n",
      "Epoch: [35/100], Step: [300/500], Loss: 0.1057\n",
      "Epoch: [35/100], Step: [400/500], Loss: 0.0955\n",
      "Epoch: [35/100], Step: [500/500], Loss: 0.0757\n",
      "Epoch: [36/100], Step: [100/500], Loss: 0.0590\n",
      "Epoch: [36/100], Step: [200/500], Loss: 0.1028\n",
      "Epoch: [36/100], Step: [300/500], Loss: 0.1097\n",
      "Epoch: [36/100], Step: [400/500], Loss: 0.1121\n",
      "Epoch: [36/100], Step: [500/500], Loss: 0.1529\n",
      "Epoch: [37/100], Step: [100/500], Loss: 0.1322\n",
      "Epoch: [37/100], Step: [200/500], Loss: 0.1141\n",
      "Epoch: [37/100], Step: [300/500], Loss: 0.1216\n",
      "Epoch: [37/100], Step: [400/500], Loss: 0.0985\n",
      "Epoch: [37/100], Step: [500/500], Loss: 0.0563\n",
      "Epoch: [38/100], Step: [100/500], Loss: 0.1406\n",
      "Epoch: [38/100], Step: [200/500], Loss: 0.0522\n",
      "Epoch: [38/100], Step: [300/500], Loss: 0.1399\n",
      "Epoch: [38/100], Step: [400/500], Loss: 0.0711\n",
      "Epoch: [38/100], Step: [500/500], Loss: 0.1232\n",
      "Epoch: [39/100], Step: [100/500], Loss: 0.1143\n",
      "Epoch: [39/100], Step: [200/500], Loss: 0.0827\n",
      "Epoch: [39/100], Step: [300/500], Loss: 0.0770\n",
      "Epoch: [39/100], Step: [400/500], Loss: 0.0894\n",
      "Epoch: [39/100], Step: [500/500], Loss: 0.0728\n",
      "Epoch: [40/100], Step: [100/500], Loss: 0.0425\n",
      "Epoch: [40/100], Step: [200/500], Loss: 0.1227\n",
      "Epoch: [40/100], Step: [300/500], Loss: 0.1182\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-46ac0dcd01a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# loop over the dataset multiple times\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_step = len(trainloader)\n",
    "for epoch in range(100):  # loop over the dataset multiple times\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1)%100 == 0:\n",
    "            print(\"Epoch: [{}/100], Step: [{}/{}], Loss: {:.4f}\".format(\n",
    "                    epoch+1, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test images: 83.86%\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in testloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _,predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    print('Accuracy of the model on the test images: {}%'.format(100*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'VGG.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_gpu]",
   "language": "python",
   "name": "conda-env-pytorch_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
